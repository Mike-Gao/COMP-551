{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "COMP 551 A2 - Team 51.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_d-inqjAVOyz"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQ4oTN_h2stw"
      },
      "source": [
        "from sklearn.datasets import load_digits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jQ0r0nU25MD",
        "outputId": "ad2826b4-2169-4c4b-863a-95544c2c7f1a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "digits_x, digits_y = load_digits(return_X_y=True)\n",
        "digits_y = digits_y.astype(int)\n",
        "print(digits_x.shape, digits_y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1797, 64) (1797,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nNOH-sLTbI1"
      },
      "source": [
        "def softmax(x):\n",
        "      return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
        "\n",
        "def one_hot_encoding(y, k):\n",
        "    one_hot = np.zeros((len(y), k))\n",
        "    one_hot[np.arange(len(y)), y] = 1\n",
        "    return one_hot\n",
        "    \n",
        "class SoftmaxRegression:\n",
        "    def __init__(self, total_cls):\n",
        "        self.total_cls = total_cls\n",
        "        self.w = None\n",
        "\n",
        "    def fit(self, x_train, y_train, x_val, y_val, optimizer):\n",
        "        N,D = x_train.shape\n",
        "        def gradient(x, y, w):\n",
        "            yh =  softmax(np.matmul(x, w))\n",
        "            grad = 1/N * np.matmul(x.T, (yh - one_hot_encoding(y, self.total_cls)))\n",
        "            return grad\n",
        "        w0 = np.zeros((D, self.total_cls))\n",
        "        self.w, history = optimizer.run(gradient, x_train, y_train, x_val, y_val, w0, self.total_cls)\n",
        "        return history\n",
        "    \n",
        "    def predict(self, x):\n",
        "        return softmax(np.matmul(x, self.w))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0bRHQ5GNvAT"
      },
      "source": [
        "from collections import defaultdict\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYNc7iqUO7zL"
      },
      "source": [
        "class MiniBatchGradientDescent:\n",
        "\n",
        "  def __init__(self, batch_size = 256, learning_rate = 0.01, momentum = 0.9, l2_regularization = 0.1, termination_step = 20):\n",
        "      self.batch_size = batch_size\n",
        "      self.learning_rate = learning_rate\n",
        "      self.momentum = momentum\n",
        "      self.l2_regularization = l2_regularization\n",
        "      self.termination_step = termination_step\n",
        "\n",
        "  def create_mini_batches(self, x):\n",
        "      lst = list(range(len(x)))\n",
        "      np.random.shuffle(lst)\n",
        "      return np.array_split(lst, self.batch_size)\n",
        "\n",
        "  def cost(self, x, y, w, k):\n",
        "      z = np.matmul(x, w)\n",
        "      z -= np.max(z)\n",
        "      return np.mean(-1 * np.sum(one_hot_encoding(y, k) * z - np.log(np.sum(np.exp(z)))))\n",
        "\n",
        "  def accuracy(self, x, y, w):\n",
        "      return mean_squared_error(np.argmax(softmax(np.matmul(x, w)), axis=1), y)\n",
        "\n",
        "\n",
        "  def run(self, gradient_function, x_train, y_train, x_validation, y_validation, w, k):\n",
        "      grad = np.inf\n",
        "      validation_best = np.inf\n",
        "      delta_w = 0\n",
        "      best_w = w.copy()\n",
        "      step = 0\n",
        "      history = defaultdict(list)\n",
        "      termination = False\n",
        "      while not termination:\n",
        "          minibatch_ttl = self.create_mini_batches(x_train)\n",
        "          for minibatch_idx in minibatch_ttl:\n",
        "              x_batch = x_train[minibatch_idx]\n",
        "              y_batch = y_train[minibatch_idx]\n",
        "              gradient = gradient_function(x_batch, y_batch, w) \n",
        "              gradient += (np.linalg.norm(w) ** 2) * self.l2_regularization * 0.5\n",
        "              delta_w = self.momentum * delta_w + (1 - self.momentum) * gradient\n",
        "              w -= self.learning_rate * delta_w\n",
        "              history[\"cost\"].append(self.cost(x_batch, y_batch, w, k))\n",
        "              history[\"train_accuracy\"].append(self.accuracy(x_batch, y_batch, w))\n",
        "              history[\"val_accuracy\"].append(self.accuracy(x_validation, y_validation, w))\n",
        "\n",
        "              validation_error = mean_squared_error(np.argmax(softmax(np.matmul(x_validation, w)), axis=1), y_validation)\n",
        "\n",
        "              if validation_error < validation_best:\n",
        "                  validation_best = validation_error\n",
        "                  best_w = w.copy()\n",
        "                  step = 0\n",
        "              else:\n",
        "                  step += 1\n",
        "                  if step >= self.termination_step:\n",
        "                      termination = True\n",
        "                      history[\"training_stop\"] = [step]\n",
        "                      break\n",
        "      return best_w, history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tp7huhNCPcdr"
      },
      "source": [
        "def k_fold_cross_val(x, k = 5):\n",
        "    lst = list(range(len(x)))\n",
        "    np.random.shuffle(lst)\n",
        "    folds = np.array_split(lst, k)\n",
        "    for i in range(k):\n",
        "        test = np.concatenate(*[folds[:i] + folds[i+1:]])\n",
        "        val = folds[i]\n",
        "        yield test.flatten(), val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITvv7EXAcQaK"
      },
      "source": [
        "def run_k_fold_cross_val(x, y, model, optimizer):\n",
        "    for i, (train_id, val_id) in enumerate(k_fold_cross_val(x)):\n",
        "        x_train, y_train = x[train_id], y[train_id]\n",
        "        x_val, y_val = x[val_id], y[val_id]\n",
        "        history = model.fit(x_train, y_train, x_val, y_val, optimizer)\n",
        "        print(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWb0VaG_dcD0",
        "outputId": "2ca07ef8-2a91-4d7f-b388-b0cb165f97ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = SoftmaxRegression(26)\n",
        "optimizer = MiniBatchGradientDescent()\n",
        "run_k_fold_cross_val(digits_x, digits_y, model, optimizer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "defaultdict(<class 'list'>, {'cost': [786.9567199602757, 786.3950408211851, 786.0092910355245, 784.6720078902863, 784.6700742016353, 783.8464075145491, 783.124824537056, 780.7191942689178, 778.6860093574289, 777.4140968995619, 776.2615708170576, 774.3893969356272, 774.9962426370764, 773.4867096397043, 773.1610929638281, 770.3127993641621, 769.6458235667561, 764.9153504748073, 767.7570296526337, 761.2392001343829, 762.0450990430984, 762.4511551315618, 761.3854732953077, 760.8830600677303, 753.415063672426, 756.4640068015951, 756.3089788731613, 752.2376261272672, 753.6409754881191, 752.7238401902923, 748.6318409649523, 746.31478888325, 746.57775152781, 743.930939026867, 741.9576018873933, 736.1802683822732, 742.803454652539, 738.6196844462552, 736.6008766965058, 740.8164930896148, 741.521827660627], 'train_accuracy': [0.0, 0.0, 11.166666666666666, 13.666666666666666, 2.8333333333333335, 1.5, 6.0, 17.666666666666668, 4.166666666666667, 3.6666666666666665, 0.16666666666666666, 1.8333333333333333, 11.0, 0.0, 10.666666666666666, 13.5, 7.666666666666667, 6.666666666666667, 10.166666666666666, 15.0, 17.833333333333332, 7.5, 0.5, 19.5, 9.0, 0.8333333333333334, 2.6666666666666665, 17.666666666666668, 0.0, 0.16666666666666666, 0.0, 6.166666666666667, 0.6666666666666666, 0.5, 10.833333333333334, 0.0, 6.0, 6.0, 4.833333333333333, 0.16666666666666666, 0.8333333333333334], 'val_accuracy': [11.694444444444445, 11.833333333333334, 11.991666666666667, 9.95, 9.902777777777779, 8.73611111111111, 8.433333333333334, 7.9, 7.613888888888889, 7.383333333333334, 7.2555555555555555, 6.738888888888889, 7.4527777777777775, 7.563888888888889, 7.527777777777778, 7.441666666666666, 7.186111111111111, 6.966666666666667, 7.086111111111111, 7.055555555555555, 6.108333333333333, 6.427777777777778, 6.316666666666666, 6.305555555555555, 6.308333333333334, 6.419444444444444, 6.477777777777778, 6.544444444444444, 6.5, 6.5, 6.666666666666667, 6.663888888888889, 6.563888888888889, 6.552777777777778, 6.6194444444444445, 6.663888888888889, 6.830555555555556, 6.963888888888889, 6.961111111111111, 6.741666666666666, 7.133333333333334], 'training_stop': [20]})\n",
            "defaultdict(<class 'list'>, {'cost': [787.0269462969396, 786.7220536869322, 786.1799445507419, 785.4803371267221, 784.3609193205061, 784.2874497388984, 782.5335035307289, 782.2565513524553, 780.1610819897763, 779.2938920543766, 777.049785555175, 776.0977209803234, 775.6650844302096, 772.0990658127357, 770.574260700412, 770.2782092848238, 762.6255754733234, 764.7068247152738, 759.0487039415241, 764.3244085223453, 761.1384326577477, 756.0239176024415, 753.3813215871919, 753.3336710610197, 756.6290036182306, 752.3852704207827, 753.5787812417958, 750.5668385067489, 752.8843308233995, 744.9085239591386, 749.227207436566, 748.2082366684447, 743.5809785414531, 747.5167265459669, 739.0936287244543, 738.4707309797265, 735.9818894705229, 741.0845783445218, 734.3160066716499, 733.7389044795058, 724.5443128246941, 731.117216356915, 724.6709258146417, 729.8691875623799, 724.6117642958409, 735.5004801171178, 721.9097488175471, 723.0134193468741, 724.8630293253204, 724.690644612509, 713.8686922944551, 713.2456126883819, 718.483752528439, 718.3315637374596, 721.4416801284864, 708.6588049600248, 720.7669909123381, 703.6382640590066, 701.230121152639, 712.1245589107668, 705.4415333682823, 702.0205729236486, 685.9650701763319, 706.3330576355887, 706.4430747940954, 691.283744861756, 692.0332263263685, 700.5451794843067, 695.6340287800354, 679.3879614581414, 686.5582398097727, 684.180088308746, 693.8512043360103, 674.3933571086864, 688.4404102321871, 689.2029790440412], 'train_accuracy': [0.0, 8.333333333333334, 6.0, 10.833333333333334, 0.0, 8.166666666666666, 0.16666666666666666, 12.0, 17.666666666666668, 2.8333333333333335, 9.0, 19.166666666666668, 2.6666666666666665, 16.833333333333332, 0.6666666666666666, 10.166666666666666, 22.333333333333332, 14.333333333333334, 0.16666666666666666, 10.5, 0.16666666666666666, 6.0, 4.166666666666667, 17.666666666666668, 1.0, 12.5, 4.333333333333333, 6.333333333333333, 8.666666666666666, 0.8333333333333334, 10.666666666666666, 10.833333333333334, 7.666666666666667, 6.666666666666667, 16.333333333333332, 16.666666666666668, 13.5, 1.5, 0.6666666666666666, 8.5, 29.666666666666668, 0.16666666666666666, 10.666666666666666, 6.166666666666667, 0.6666666666666666, 19.5, 0.0, 9.5, 0.0, 15.0, 8.166666666666666, 2.6666666666666665, 0.0, 27.166666666666668, 6.166666666666667, 0.16666666666666666, 25.5, 1.5, 2.8333333333333335, 4.166666666666667, 0.0, 0.0, 10.166666666666666, 10.666666666666666, 0.0, 8.166666666666666, 4.333333333333333, 15.666666666666666, 18.166666666666668, 10.833333333333334, 0.8333333333333334, 0.16666666666666666, 0.8333333333333334, 2.6666666666666665, 0.6666666666666666, 1.5], 'val_accuracy': [14.994444444444444, 9.85, 9.658333333333333, 9.661111111111111, 9.761111111111111, 9.488888888888889, 9.644444444444444, 9.119444444444444, 8.641666666666667, 8.719444444444445, 8.272222222222222, 8.411111111111111, 8.73611111111111, 8.708333333333334, 8.722222222222221, 8.430555555555555, 7.622222222222222, 7.308333333333334, 6.872222222222222, 6.830555555555556, 6.988888888888889, 6.663888888888889, 6.252777777777778, 6.3694444444444445, 6.708333333333333, 6.583333333333333, 6.647222222222222, 6.902777777777778, 6.747222222222222, 6.858333333333333, 6.858333333333333, 6.983333333333333, 6.902777777777778, 6.980555555555555, 6.775, 6.775, 6.988888888888889, 7.311111111111111, 7.311111111111111, 6.572222222222222, 6.208333333333333, 6.094444444444444, 5.902777777777778, 5.902777777777778, 5.902777777777778, 5.808333333333334, 5.808333333333334, 5.583333333333333, 5.572222222222222, 5.572222222222222, 5.572222222222222, 5.572222222222222, 5.572222222222222, 5.472222222222222, 5.475, 5.05, 5.05, 5.05, 5.05, 5.186111111111111, 5.286111111111111, 5.280555555555556, 5.530555555555556, 5.483333333333333, 5.483333333333333, 5.508333333333334, 5.583333333333333, 5.730555555555555, 5.766666666666667, 5.991666666666666, 6.122222222222222, 6.0777777777777775, 5.941666666666666, 5.941666666666666, 6.041666666666667, 6.041666666666667], 'training_stop': [20]})\n",
            "defaultdict(<class 'list'>, {'cost': [787.0208257288787, 786.006100843664, 785.1054268181335, 783.3849595903416, 783.3118236901854, 779.3653393420867, 780.1436739324756, 776.2329119594349, 776.4658578942126, 777.4859202222311, 775.2735739918305, 772.1361312952217, 771.3177565775231, 773.2731194503235, 768.05539731567, 763.9962860008143, 766.4257919253769, 757.982994367383, 762.5818463888261, 759.2650570314275, 761.6304262248816, 758.2136663707493, 749.1903811527437, 754.6951703247398, 753.1247737671627, 745.7386097999384, 751.1394034107573, 743.1277704392646, 754.0960377919671, 737.1301843803302, 743.9367306872873, 742.5687318296845, 741.4419938742075, 734.8811210744692, 737.1694226522673, 743.2350113614167, 730.2164894229966, 736.276456782367, 726.7910001230182, 723.9572667502076, 721.187260016836, 730.2526498440899, 731.2663317048983, 719.843540782447, 727.215579889094, 719.7399077456378, 732.4034998898193, 709.6799288661512, 722.8154798450719, 716.0315952578176, 707.4969283790748, 708.9353507853166, 717.6758973065887, 715.8853764716289, 698.5911169368649, 700.0479873497212], 'train_accuracy': [0.0, 0.16666666666666666, 10.166666666666666, 0.16666666666666666, 19.333333333333332, 0.3333333333333333, 7.0, 6.0, 11.0, 43.666666666666664, 0.16666666666666666, 2.8333333333333335, 12.5, 1.3333333333333333, 2.1666666666666665, 9.666666666666666, 3.5, 6.0, 10.166666666666666, 4.166666666666667, 0.6666666666666666, 21.666666666666668, 11.0, 7.333333333333333, 13.166666666666666, 1.5, 14.166666666666666, 19.0, 18.333333333333332, 8.166666666666666, 0.6666666666666666, 6.0, 25.5, 0.0, 1.5, 1.6666666666666667, 0.0, 0.16666666666666666, 3.3333333333333335, 16.666666666666668, 1.5, 11.0, 17.0, 8.333333333333334, 13.166666666666666, 8.166666666666666, 10.333333333333334, 0.16666666666666666, 3.0, 6.0, 0.6666666666666666, 2.1666666666666665, 1.3333333333333333, 4.833333333333333, 1.5, 8.833333333333334], 'val_accuracy': [16.860724233983287, 14.919220055710307, 14.314763231197771, 14.45125348189415, 16.16434540389972, 16.214484679665738, 15.732590529247911, 15.551532033426184, 15.147632311977716, 14.26183844011142, 11.470752089136491, 10.442896935933147, 10.325905292479108, 9.877437325905293, 9.587743732590528, 9.423398328690809, 8.529247910863509, 8.07799442896936, 7.888579387186629, 7.562674094707521, 7.011142061281337, 6.275766016713092, 6.203342618384401, 5.554317548746518, 5.2534818941504176, 4.991643454038997, 4.774373259052925, 4.774373259052925, 4.412256267409471, 4.3983286908078, 4.334261838440112, 4.47075208913649, 4.395543175487465, 4.337047353760446, 4.4094707520891365, 4.181058495821727, 4.281337047353761, 4.281337047353761, 4.554317548746518, 4.554317548746518, 4.554317548746518, 4.754874651810585, 4.757660167130919, 4.727019498607242, 4.6155988857938715, 4.579387186629527, 4.593314763231198, 4.782729805013927, 4.635097493036212, 4.610027855153203, 4.610027855153203, 4.598885793871866, 4.721448467966574, 4.749303621169917, 4.885793871866295, 4.860724233983287], 'training_stop': [20]})\n",
            "defaultdict(<class 'list'>, {'cost': [787.0104409107595, 786.8105847940751, 786.0150762592007, 785.622170285582, 784.9321551552382, 783.5911678288297, 782.1979357972173, 781.7415170469185, 777.4689297780783, 778.3523250998076, 778.237009257389, 773.5926621576484, 770.959449156914, 770.2816002516047, 770.3923487742304, 765.6199239803057, 767.5002388227334, 761.4907406554023, 761.0992491900763, 762.1602948071477, 757.7002315387006, 756.1195644638135, 752.8268260837405, 756.2980339209475, 748.3569827849794, 749.1705355144163, 743.8551027706841, 740.1167754649166, 744.1979399059503, 738.9873192290911, 737.5880313493433, 743.7555939067555, 737.6471014608803, 733.0087471306219, 735.2902883703814, 726.4930281590891, 733.4966352013532, 734.3603587959805, 732.8401041182346, 723.3569192554162, 723.4230278616634, 718.0985918008807, 727.0010731717663, 724.5436486832766, 714.2251365594361, 720.8394896915491, 718.7598035704157, 722.5862190663145, 713.9848891387909, 716.4603037540923, 711.510731976625, 706.5702391696743, 724.750338829827, 708.4043059285309, 708.9897461881658, 702.811430006911, 714.5308301466928, 711.0969102645097, 688.8571448163184, 709.0532029417536, 695.5631345512866, 686.6794925430488, 699.820209387882], 'train_accuracy': [0.0, 8.166666666666666, 2.3333333333333335, 0.6666666666666666, 13.666666666666666, 8.333333333333334, 4.333333333333333, 2.6666666666666665, 2.3333333333333335, 10.166666666666666, 34.5, 6.0, 1.5, 10.5, 6.166666666666667, 4.166666666666667, 0.6666666666666666, 6.0, 20.833333333333332, 1.0, 18.166666666666668, 4.166666666666667, 1.6666666666666667, 7.666666666666667, 19.0, 10.166666666666666, 3.3333333333333335, 4.166666666666667, 4.333333333333333, 13.5, 6.166666666666667, 9.0, 6.5, 12.0, 5.333333333333333, 8.333333333333334, 22.666666666666668, 12.333333333333334, 20.666666666666668, 4.166666666666667, 10.666666666666666, 0.0, 10.166666666666666, 0.6666666666666666, 1.6666666666666667, 0.6666666666666666, 0.16666666666666666, 10.666666666666666, 18.833333333333332, 13.666666666666666, 9.0, 0.0, 0.0, 8.5, 12.166666666666666, 0.0, 0.6666666666666666, 10.333333333333334, 11.5, 4.833333333333333, 0.0, 7.5, 8.333333333333334], 'val_accuracy': [14.47632311977716, 10.835654596100278, 8.133704735376044, 8.866295264623956, 8.33983286908078, 7.52924791086351, 7.3008356545961, 7.3175487465181055, 7.395543175487465, 7.417827298050139, 7.534818941504178, 7.105849582172702, 7.142061281337047, 6.910863509749303, 6.557103064066852, 6.9164345403899725, 6.579387186629527, 6.417827298050139, 6.493036211699164, 6.52924791086351, 6.5264623955431755, 6.5013927576601676, 6.593314763231198, 6.612813370473537, 6.378830083565459, 6.484679665738161, 6.596100278551532, 6.4986072423398324, 6.688022284122563, 6.632311977715878, 6.571030640668524, 6.3314763231197775, 6.164345403899722, 6.125348189415042, 21.506963788300837, 5.623955431754875, 5.894150417827298, 5.743732590529248, 5.598885793871866, 5.520891364902507, 5.420612813370473, 5.417827298050139, 5.303621169916434, 5.548746518105849, 5.370473537604457, 5.370473537604457, 5.392757660167131, 5.367688022284122, 5.50974930362117, 5.50974930362117, 5.50974930362117, 5.688022284122563, 5.757660167130919, 5.788300835654596, 5.8245125348189415, 5.986072423398329, 5.986072423398329, 5.7604456824512535, 5.7604456824512535, 5.757660167130919, 5.757660167130919, 5.7325905292479105, 5.52924791086351], 'training_stop': [20]})\n",
            "defaultdict(<class 'list'>, {'cost': [786.9276554841812, 786.4890205192285, 786.0663262370545, 784.4383912976984, 784.1630360455508, 782.5772307043453, 782.5908121246014, 780.4178366322003, 778.922895947669, 778.5018603250387, 776.8005864630312, 775.2089000761727, 773.7151925417904, 771.0561542462317, 768.5027255383559, 768.9643506315484, 767.5109199443679, 765.5360386060765, 763.8514099701321, 759.1380924136863, 762.6465017228661, 754.0711083905644, 757.909606951098, 755.2210303769895, 754.9259760785882, 748.880326479627, 750.2721884867742, 745.1485290132571, 748.201257173211, 741.7517708782341, 746.0096935557815, 739.1753529165178, 743.8318707918243, 742.7407177497098, 732.4123137378231, 734.7411423086606, 734.5414040117855, 731.0982012804175], 'train_accuracy': [0.0, 0.0, 1.5, 6.833333333333333, 13.5, 0.6666666666666666, 6.0, 6.0, 0.0, 21.833333333333332, 0.8333333333333334, 10.666666666666666, 16.833333333333332, 0.0, 0.16666666666666666, 1.5, 15.833333333333334, 6.0, 0.8333333333333334, 0.16666666666666666, 14.833333333333334, 0.0, 32.5, 0.0, 4.833333333333333, 0.0, 4.833333333333333, 17.666666666666668, 6.166666666666667, 0.0, 0.3333333333333333, 0.6666666666666666, 10.166666666666666, 21.833333333333332, 16.333333333333332, 0.6666666666666666, 12.5, 6.666666666666667], 'val_accuracy': [20.323119777158773, 15.32033426183844, 12.038997214484679, 9.754874651810585, 9.066852367688023, 8.754874651810585, 8.080779944289693, 8.348189415041782, 8.097493036211699, 7.972144846796658, 7.626740947075209, 7.373259052924791, 7.348189415041783, 7.32033426183844, 6.977715877437326, 7.036211699164346, 7.011142061281337, 6.913649025069638, 7.298050139275766, 7.5905292479108635, 7.612813370473537, 7.604456824512535, 7.3008356545961, 7.233983286908078, 7.20891364902507, 7.345403899721449, 7.197771587743732, 7.289693593314763, 7.178272980501393, 7.211699164345404, 7.387186629526463, 7.250696378830083, 7.144846796657381, 7.281337047353761, 7.2534818941504176, 7.231197771587744, 7.1754874651810585, 7.289693593314763], 'training_stop': [20]})\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}